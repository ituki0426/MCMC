
## 6.2.ギブスサンプリング法（熱浴法）

メトロポリス法やHMC法はありとあらゆるケースに適用できる。

これから説明するギブスサンプリング（物理業界では熱浴法）は、適用できる場面は限られるが、適用可能な場合には効率が良いアルゴリズム。

メイズ統計などでよく使われる比較的素直な分布に対しては適用可能なことが多く、本書でも7.2.2節（ギブスサンプリングのイジング模型への適用例）でその威力を発揮します。


具体的には、確率分布を条件付き確率分布に無理やり分解して一変量ずつサンプリングしようという作戦で、マルコフ性を仮定してます。

たとえばp(x,y)という２変量の同時分布からサンプリングするよりもp(x|y)の方が簡単

次元が一つ減ってるようなものだから

導入として、ガウス分布を題材にしてアルゴリズムを説明します。

２変数の確率分布P(x,y)をメトロポリス法で構成する際、「ｙを固定してｘを少し動かす」という操作と「ｘを固定してｙを少し動かす」という操作を組み合わせればよいことはすでに説明した。

メトロポリス法はありとあらゆる問題に適用可能な強力な手法ではあるものの、ｘとやが少しずつしか変わらないため、自己相関が強くあまり効率が良くないことも説明したとおりです。

自己相関を減らすには、「ｙを固定してｘを大幅に動かす」という操作と「ｘを固定してｙを大幅に動かす」という操作を組み合わせればよいのは明らかだと思います。

ギブスサンプリングは、この至極単純な発想に基づいています。

## 6.2.0.多次元ガウス分布の定義

ガウス分布は、平均ベクトルμ、分散共分散行列Σを用いて、次の式で定義されます。

$$
\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \boldsymbol{\Sigma}) = \frac{1}{\sqrt{(2\pi)^D |\boldsymbol{\Sigma}|}} \exp \left( -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \right)
$$


x、μはD次元ベクトル、ΣはD×Dの行列です。

$$
\mathbf{x} = \begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_D
\end{pmatrix},
\quad
\boldsymbol{\mu} = \begin{pmatrix}
\mu_1 \\
\mu_2 \\
\vdots \\
\mu_D
\end{pmatrix},
\quad
\boldsymbol{\Sigma} = \begin{pmatrix}
\sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
\sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
\end{pmatrix}
$$

$\sigma_d$ は $x_d$ の標準偏差、$\sigma_d^2 = \sigma_{d,d}$ は $x_d$ の分散、$\sigma_{i,j}$ は $x_i$ と $x_j$ の共分散です。

今回は $D = 2$ でやります。平均と分散は次のように設定します。

$$
\mu = 0
$$

$$
\Sigma^{-1} = \begin{pmatrix}
1 & -a \\
-a & 1
\end{pmatrix}
$$

ただし、$-1 < a < 1$ とします。逆行列と行列式も先に計算しておきます。

$$
\Sigma = \frac{1}{1 - a^2} \begin{pmatrix}
1 & a \\
a & 1
\end{pmatrix}
$$

$$
|\Sigma| = \frac{1}{1 - a^2}
$$

$$
p(x) = p(x_1, x_2)
$$

$$
p(x_1, x_2) = \frac{1}{\sqrt{(2\pi)^2 |\Sigma|}} \exp \left\{ -\frac{1}{2} (x_1, x_2) \Sigma^{-1} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} (x_1, x_2) \begin{pmatrix} 1 & -a \\ -a & 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} (x_1 - a x_2, -a x_1 + x_2) \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( x_1^2 - a x_1 x_2 - a x_1 x_2 + x_2^2 \right) \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( x_1^2 - 2 a x_1 x_2 + x_2^2 \right) \right\}
$$

$p(x_2)$ はすべての可能な $x_1$ の値に対して $p(x_1,x_2)$ を積分した結果なので、

$$
p(x_2) = \int p(x_1, x_2) dx_1
$$

となります。
 
また、条件付確率は

$$
p(x_1 | x_2) = \frac{p(x_1, x_2)}{p(x_2)} = \frac{p(x_1, x_2)}{\int p(x_1, x_2) dx_1}
$$

となり、先ほどの式を平方完成すると分母の周辺化が容易になるので

$$
p(x_1, x_2) = \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( (x_1 - a x_2)^2 - a^2 x_2^2 + x_2^2 \right) \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( (1 - a^2) x_2^2 + (x_1 - a x_2)^2 \right) \right\}
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( (1 - a^2) x_2^2 \right) \right\} \exp \left\{ -\frac{1}{2} \left( (x_1 - a x_2)^2 \right) \right\}
$$

と、平方完成しました。あとはガッツリ積分していって条件付き確率を導出します。

$$
\int p(x_1, x_2) \, dx_1 = \int \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} (1 - a^2) x_2^2 \right\} \exp \left\{ -\frac{1}{2} (x_1 - a x_2)^2 \right\} dx_1
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} (1 - a^2) x_2^2 \right\} \int \exp \left\{ -\frac{1}{2} (x_1 - a x_2)^2 \right\} dx_1
$$

今、$x_1$ 以外は固定しているので定数とみなせます。

$$
\int p(x_1, x_2) \, dx_1 = \frac{\sqrt{1 - a^2}}{2\pi} \exp \left( -\frac{1}{2} (1 - a^2) x_2^2 \right) \int \exp \left( -\frac{1}{2} t^2 \right) dt
$$

あとはガウス積分を用いて

$$
\int \exp(-a x^2) \, dx = \sqrt{\frac{\pi}{a}}
$$

$$
\int p(x_1, x_2) \, dx_1 = \frac{\sqrt{1 - a^2}}{2\pi} \exp \left( -\frac{1}{2} (1 - a^2) x_2^2 \right) \sqrt{2\pi}
$$

$$
= \sqrt{\frac{1 - a^2}{2\pi}} \exp \left( -\frac{1}{2} (1 - a^2) x_2^2 \right)
$$

周辺化も計算できたことなので条件付確率を改めて計算すると

$$
p(x_1 | x_2) = \frac{p(x_1, x_2)}{\int p(x_1, x_2) \, dx_1}
$$

$$
= \frac{\frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} (1 - a^2) x_2^2 \right\} \exp \left\{ -\frac{1}{2} (x_1 - a x_2)^2 \right\}}{\sqrt{\frac{1 - a^2}{2\pi}} \exp \left\{ -\frac{1}{2} (1 - a^2) x_2^2 \right\}}
$$

$$
= \frac{1}{\sqrt{2\pi}} \exp \left\{ -\frac{1}{2} (x_1 - a x_2)^2 \right\}
$$

## 6.2.1.２次元ガウス分布の場合

まず、二次元、分散が１，互いに相関のないガウス分布を考えます。

このとき、分散共分散行列Σは次のようになります。

$$
\Sigma = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}
$$
したがって、確率分布は


$$
p(x_1, x_2) = \frac{1}{\sqrt{(2\pi)^2 |\Sigma|}} \exp \left( -\frac{1}{2} \begin{pmatrix} x_1 & x_2 \end{pmatrix} \Sigma^{-1} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} \right)
$$

次に、
$$
\Sigma^{-1} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}
$$

なので、内積部分も次のように簡単化できます。

$$
\begin{pmatrix} x_1 & x_2 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = x_1^2 + x_2^2
$$

$$
p(x_1, x_2) = \frac{1}{2\pi} \exp\left( -\frac{1}{2}(x_1^2 + x_2^2) \right)
$$

より、作用S(x,y)は
$$
S(x, y) = \frac{x^2 + y^2}{2}
$$

を考えてみる。

この場合はｘとｙは独立で、確率分布は以下のようにｘの確率分布とｙの確率分布の積になります：

$$
P(x, y) = P(x) \cdot P(y) = \frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}} \cdot \frac{e^{-\frac{y^2}{2}}}{\sqrt{2\pi}}
$$

したがって、ｘとｙの分布Ｐ（ｘ）、Ｐ（ｙ）を独立に作ればよい。

これは、ボックス・ミュラー法を用いれば簡単にできる。

この問題を少しだけ変えてみる。

変数ｘとｙの共分散が1/2のとき、すなわち、

$$
\Sigma = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}
$$
において、a=1/2のときを考える。
すると、上記で示した式


$$
p(x) = p(x_1, x_2)
$$

$$
= \frac{\sqrt{1 - a^2}}{2\pi} \exp \left\{ -\frac{1}{2} \left( x_1^2 - 2 a x_1 x_2 + x_2^2 \right) \right\}
$$

より、作用S(x,y)は

$$
S(x, y) = \frac{x^2 + y^2 + xy}{2}
$$


これは変数返還で前と同じ形に持っていって解くこともできるが、ここはあえてギブスサンプリングを用いる。

条件付確率P（ｘ｜ｙ）をい、ｙの値が固定されているときのｘの確率分布と定義する。

同様に、Ｐ（ｙ｜ｘ）をｘの値が固定されているときのｙの確率分布とする。

上記で証明したように、条件付確率は

$$
P(x|y) = \frac{e^{-\frac{1}{2} \left( x + \frac{y}{2} \right)^2}}{\sqrt{2\pi}}
$$

$$
P(y|x) = \frac{e^{-\frac{1}{2} \left( y + \frac{x}{2} \right)^2}}{\sqrt{2\pi}}
$$

これらの分布はボックス・ミュラー法で作ったガウス分布を-y/2あるいは-x/2だけ平行移動して簡単に作れる。

ギブスサンプリングではこの条件付き確率を活用します。

具体的には次のような手順を踏みます。

２変数のギブスサンプリング

1. $(x^{(k)}, y^{(k)})$ が得られていたとする。  
   この時、 $x^{(k + 1)}$ を確率分布 $P(x^{(k + 1)} | y^{(k)})$ で生成する。

2. 次に $y^{(k + 1)}$ を確率分布 $P(y^{(k + 1)} | x^{(k + 1)})$ で生成する。

3. 以上をひたすら繰り返す。

ポイントは、 $x^{(k)}$ を少しだけ変えて $x^{(k+1)}$ を作るのではなく、 $x^{(k)}$ とは関係なしに $x^{(k)}$ を作っていることです。


これが可能なのは今回のガウス分布のように条件付確率が簡単に計算できる形をしているときに限られるので、メトロポリス法やHMC法と比べると使える場面は限られる。

しかし、ひとたび型にハマれば、自己相関が小さいサンプルを生成できるうえ、パラメータ調整をする必要もないので大変便利です。

このやり方でマルコフ連鎖モンテカルロ法の条件が満たされることを確認する。
## 6.2.2.一般の多変数の場合

一般の多変数のギブスサンプリングは次のようになります。

1.

2.

3.

4
